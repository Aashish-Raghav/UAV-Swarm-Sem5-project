{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11839ce5",
   "metadata": {},
   "source": [
    "# Ensure kernel not breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8b11a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mConnection is disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05e6ae",
   "metadata": {},
   "source": [
    "# All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO,DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import tensorboard\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.logger import configure\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eaad8",
   "metadata": {},
   "source": [
    "# UAV class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec79b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UAV class representing a UAV node\n",
    "class UAV:\n",
    "    def __init__(self, uav_id, position):\n",
    "        self.uav_id = uav_id\n",
    "        self.position = position  # (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e9f55",
   "metadata": {},
   "source": [
    "# Cluster Head class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClusterHead class representing a cluster head node\n",
    "class ClusterHead:\n",
    "    def __init__(self, head_id, position):\n",
    "        self.head_id = head_id\n",
    "        self.position = position  # (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4672c0",
   "metadata": {},
   "source": [
    "# UAV Swarm Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07daa612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom environment using gymnasium\n",
    "class UAVSwarmEnv(gym.Env):\n",
    "    def __init__(self, grid_size, num_cluster_heads, transmission_range, num_uavs):\n",
    "        super(UAVSwarmEnv, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_cluster_heads = num_cluster_heads\n",
    "        self.transmission_range = transmission_range\n",
    "        self.efficient_threshold = self.transmission_range * 0.8\n",
    "        self.num_uavs = num_uavs\n",
    "        self.cluster_heads = []\n",
    "        self.uavs = []\n",
    "        self.current_step = 0\n",
    "        \n",
    "        self.setup_environment()\n",
    "\n",
    "        # Define action and observation space\n",
    "        self.action_space = gym.spaces.Discrete(num_uavs*5)  # Each action corresponds to a UAV's action\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=grid_size, shape=(2, num_cluster_heads), dtype=np.float32)\n",
    "\n",
    "    def setup_environment(self):\n",
    "        # Place cluster heads while ensuring distance constraints\n",
    "        positions = []\n",
    "        while len(self.cluster_heads) < self.num_cluster_heads:\n",
    "            position = (random.uniform(0, self.grid_size), random.uniform(0, self.grid_size))\n",
    "            if self.is_valid_position(position, positions):\n",
    "                self.cluster_heads.append(ClusterHead(len(self.cluster_heads), position))\n",
    "                positions.append(position)\n",
    "\n",
    "        # Place UAVs randomly in the grid\n",
    "        for uav_id in range(self.num_uavs):\n",
    "            uav_position = (random.uniform(0, self.grid_size), random.uniform(0, self.grid_size))\\\n",
    "            # uav_position = (0,0)\n",
    "            self.uavs.append(UAV(uav_id=uav_id, position=uav_position))\n",
    "\n",
    "    def is_valid_position(self, new_position, existing_positions):\n",
    "        for pos in existing_positions:\n",
    "            distance = np.linalg.norm(np.array(new_position) - np.array(pos))\n",
    "            if distance <= 2 * self.transmission_range:\n",
    "                return False  # Too close to another cluster head\n",
    "        return True\n",
    "\n",
    "    def step(self, action):\n",
    "        # Determine which UAV to move and in which direction\n",
    "        num_uavs = len(self.uavs)\n",
    "        uav_index = action // 5  # Adjusted for 5 actions: 4 directions + stay\n",
    "        move_direction = action % 5  # Adjusted for the new action set\n",
    "    \n",
    "        # Validate UAV index\n",
    "        if uav_index >= num_uavs:\n",
    "            raise ValueError(\"Invalid action, UAV index out of bounds\")\n",
    "    \n",
    "        # Select the UAV based on the action\n",
    "        uav = self.uavs[uav_index]\n",
    "        previous_position = uav.position  # Save the previous position\n",
    "    \n",
    "        # Define movement: 0 = stay, 1 = right, 2 = left, 3 = up, 4 = down\n",
    "        if move_direction == 0:\n",
    "            move = (0,0)\n",
    "            pass\n",
    "        elif move_direction == 1:\n",
    "            move = (1, 0)  # Move right\n",
    "        elif move_direction == 2:\n",
    "            move = (-1, 0)  # Move left\n",
    "        elif move_direction == 3:\n",
    "            move = (0, 1)  # Move up\n",
    "        elif move_direction == 4:\n",
    "            move = (0, -1)  # Move down\n",
    "    \n",
    "        # Apply movement within the grid boundaries\n",
    "        uav.position = (max(0, min(self.grid_size, uav.position[0] + move[0])),\n",
    "                        max(0, min(self.grid_size, uav.position[1] + move[1])))\n",
    "    \n",
    "        # Calculate the reward\n",
    "        reward = self.calculate_reward(uav, previous_position)\n",
    "    \n",
    "        # Update the environment state\n",
    "        self.current_step += 1\n",
    "    \n",
    "        # Define termination conditions\n",
    "        terminated = False  # Custom termination condition\n",
    "        truncated = self.current_step >= 100  # Example: episode ends after 100 steps\n",
    "    \n",
    "        # Return observation, reward, termination status, truncation status, and additional info\n",
    "        return self.get_observation(), reward, terminated, truncated, {}\n",
    "\n",
    "    def calculate_reward(self, uav, previous_position):\n",
    "        # Initialize reward\n",
    "        reward = 0\n",
    "    \n",
    "        # Check direct connections established and reward based on their quality\n",
    "        for i, ch1 in enumerate(self.cluster_heads):\n",
    "            for ch2 in self.cluster_heads[i + 1:]:\n",
    "                if self.can_communicate(ch1, ch2):\n",
    "                    # Reward based on the distance between cluster heads\n",
    "                    distance_between_chs = self.distance(ch1.position, ch2.position)\n",
    "                    reward += max(0, 10 - distance_between_chs)  # Closer connections yield higher rewards\n",
    "    \n",
    "        # Reward based on the distance the UAV moved, encouraging efficient movement\n",
    "        distance_moved = np.linalg.norm(np.array(uav.position) - np.array(previous_position))\n",
    "        if distance_moved > 0:\n",
    "            # Reward exploration with diminishing returns to prevent excessive movement without purpose\n",
    "            reward += min(5, distance_moved)  # Cap the reward for movement\n",
    "    \n",
    "        # Check if the UAV has moved closer to any cluster head\n",
    "        closest_ch = self.get_closest_cluster_head(uav)\n",
    "        if closest_ch and self.distance(uav.position, closest_ch.position) < self.transmission_range:\n",
    "            reward += 5  # Bonus for getting close to a cluster head\n",
    "    \n",
    "        # Penalty for too many steps without connections\n",
    "        if self.current_step % 10 == 0:  # Every 10 steps\n",
    "            if not any(self.can_communicate(ch1, ch2) for ch1 in self.cluster_heads for ch2 in self.cluster_heads):\n",
    "                reward -= 0.5 * (self.current_step // 10)  # Increase penalty based on inactivity\n",
    "    \n",
    "        # Energy efficiency consideration\n",
    "        energy_used = self.calculate_energy_usage(previous_position)  # Assume this function calculates energy usage\n",
    "        if energy_used > self.efficient_threshold:\n",
    "            reward -= (energy_used - self.efficient_threshold) * 0.1  # Penalize excess energy use\n",
    "    \n",
    "        # Reward for achieving specific goals, if applicable\n",
    "        # if self.goal_achieved():\n",
    "        #     reward += 20  # Significant reward for achieving the goal\n",
    "    \n",
    "        return reward\n",
    "    \n",
    "    def distance(self, pos1, pos2):\n",
    "        \"\"\"Calculate the Euclidean distance between two positions.\"\"\"\n",
    "        return np.linalg.norm(np.array(pos1) - np.array(pos2))\n",
    "    \n",
    "    def can_communicate(self, ch1, ch2):\n",
    "        \"\"\"Determine if two cluster heads can communicate based on their distance.\"\"\"\n",
    "        return self.distance(ch1.position, ch2.position) <= self.transmission_range\n",
    "    \n",
    "    def get_closest_cluster_head(self, uav):\n",
    "        \"\"\"Find the closest cluster head to the given UAV.\"\"\"\n",
    "        closest_ch = None\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for ch in self.cluster_heads:\n",
    "            dist = self.distance(uav.position, ch.position)\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                closest_ch = ch\n",
    "                \n",
    "        return closest_ch\n",
    "    \n",
    "    def calculate_energy_usage(self,previous_position):\n",
    "        \"\"\"Calculate the energy used by the UAVs during movements and communications.\"\"\"\n",
    "        # Implement your energy calculation logic here\n",
    "        # For example, a simple model could be:\n",
    "        energy_used = sum(np.linalg.norm(np.array(uav.position) - np.array(previous_position)) \n",
    "                            for uav in self.uavs)\n",
    "        return energy_used\n",
    "\n",
    "    # def goal_achieved(self):\n",
    "    #     \"\"\"Check if the UAVs have completed their mission or achieved a specific goal.\"\"\"\n",
    "    #     # Define the logic to determine if a goal is achieved\n",
    "    #     # For example, it might involve checking the number of connections or the distance to a target\n",
    "    #     return self.some_condition_for_goal_completion  # Replace with actual condition\n",
    "\n",
    "\n",
    "\n",
    "    def can_communicate(self, start_ch, target_ch):\n",
    "        visited = set()  # To keep track of visited nodes\n",
    "        queue = [start_ch]  # Start BFS with the initial cluster \n",
    "        while queue:\n",
    "            current = queue.pop(0)  # Dequeue the first cluster head\n",
    "            if current.head_id == target_ch.head_id:\n",
    "                return True  # Found the target cluster head\n",
    "\n",
    "            # Check for communication through UAVs\n",
    "            for uav in self.uavs:\n",
    "                dist_start = np.linalg.norm(np.array(current.position) - np.array(uav.position))\n",
    "                if dist_start <= 2*self.transmission_range:  # Can communicate with UAV\n",
    "                    # Check other cluster heads for communication through the same UAV\n",
    "                    for other_ch in self.cluster_heads:\n",
    "                        if other_ch.head_id != current.head_id:  # Avoid self-loop\n",
    "                            dist_other = np.linalg.norm(np.array(other_ch.position) - np.array(uav.position))\n",
    "                            if dist_other <= 2*self.transmission_range and other_ch not in visited:\n",
    "                                visited.add(other_ch)  # Mark as visited\n",
    "                                queue.append(other_ch)  # Enqueue for further exploration\n",
    "                                \n",
    "        return False  # No path found to the target cluster head\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)  # Ensure the seed is passed to the parent class\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "            \n",
    "        self.cluster_heads = []\n",
    "        self.uavs = []\n",
    "        self.current_step = 0\n",
    "        self.setup_environment()  # Reinitialize environment\n",
    "        initial_observation = self.get_observation()\n",
    "        info = {}  # You can include any additional info here if needed in the future\n",
    "        return (initial_observation,info)\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_observation(self):\n",
    "        # Return the positions of cluster heads as the observation\n",
    "        observation = np.zeros((2, self.num_cluster_heads), dtype=np.float32)  # Ensure dtype is float32\n",
    "        for i, ch in enumerate(self.cluster_heads):\n",
    "            observation[0, i] = float(ch.position[0])  # Cast to float\n",
    "            observation[1, i] = float(ch.position[1])  # Cast to float\n",
    "        return observation\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        \n",
    "        # Render Cluster Heads\n",
    "        for i, ch in enumerate(self.cluster_heads):\n",
    "            plt.scatter(ch.position[0], ch.position[1], color='red', s=200, marker='o', label='Cluster Head' if i == 0 else \"\")\n",
    "            # Draw transmission range area\n",
    "            circle = plt.Circle(ch.position, self.transmission_range, color='red', alpha=0.1)\n",
    "            plt.gca().add_patch(circle)\n",
    "        \n",
    "        # Render UAVs\n",
    "        for i, uav in enumerate(self.uavs):\n",
    "            plt.scatter(uav.position[0], uav.position[1], color='blue', s=100, marker='x', label='UAV' if i == 0 else \"\")\n",
    "            # Draw transmission range area\n",
    "            circle = plt.Circle(uav.position, self.transmission_range, color='blue', alpha=0.1)\n",
    "            plt.gca().add_patch(circle)\n",
    "        \n",
    "        # Set plot limits and labels\n",
    "        plt.xlim(0, self.grid_size)\n",
    "        plt.ylim(0, self.grid_size)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.title(\"UAV Swarm Environment\")\n",
    "        plt.xlabel(\"X Position\")\n",
    "        plt.ylabel(\"Y Position\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Display legend (only if cluster heads and UAVs are non-empty)\n",
    "        if len(self.cluster_heads) > 0 or len(self.uavs) > 0:\n",
    "            plt.legend(loc='upper right')\n",
    "        \n",
    "        # Handle mode: 'human' or 'rgb_array'\n",
    "        if mode == 'human':\n",
    "            plt.show()  # Display plot for human mode\n",
    "        elif mode == 'rgb_array':\n",
    "            # Save plot to a numpy array and return the RGB image\n",
    "            plt.gca().figure.canvas.draw()\n",
    "            # Use buffer_rgba to get the RGBA image\n",
    "            image = np.frombuffer(plt.gca().figure.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "            # Convert to the proper shape\n",
    "            image = image.reshape(plt.gca().figure.canvas.get_width_height()[::-1] + (4,))\n",
    "            plt.close()  # Close the plot to avoid overlapping\n",
    "            return image\n",
    "        \n",
    "        \n",
    "        \n",
    "            # Custom legend to avoid duplicates\n",
    "            handles, labels = plt.gca().get_legend_handles_labels()\n",
    "            by_label = dict(zip(labels, handles))\n",
    "            plt.legend(by_label.values(), by_label.keys())\n",
    "        \n",
    "            plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f894a",
   "metadata": {},
   "source": [
    "# create and render Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5372a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UAVSwarmEnv(grid_size=100, num_cluster_heads=10, transmission_range=10, num_uavs=5)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9619f",
   "metadata": {},
   "source": [
    "# check environment with openai gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb0703",
   "metadata": {},
   "source": [
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging and saving directories\n",
    "log_path = \"./logs/\"\n",
    "save_path = \"./models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = EvalCallback(env, log_path=log_path, eval_freq=1000, best_model_save_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PPO model\n",
    "model = PPO(\n",
    "    \"MlpPolicy\", \n",
    "    env, \n",
    "    learning_rate=3e-4, \n",
    "    n_steps=2048, \n",
    "    n_epochs=5,\n",
    "    batch_size=64, \n",
    "    ent_coef=0.01, \n",
    "    gamma=0.99, \n",
    "    clip_range=0.2, \n",
    "    verbose=1, \n",
    "    tensorboard_log=log_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25928db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bcf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path + \"ppo_uav_swarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(\n",
    "    \"MlpPolicy\",                 # DQN uses MlpPolicy for neural networks\n",
    "    env,                         # The environment\n",
    "    learning_rate=3e-4,          # Learning rate for the model\n",
    "    buffer_size=1000000,         # Replay buffer size\n",
    "    learning_starts=50000,       # Number of steps before learning starts\n",
    "    batch_size=64,               # Mini-batch size\n",
    "    tau=1.0,                     # Soft update coefficient for target network\n",
    "    gamma=0.99,                  # Discount factor\n",
    "    train_freq=4,                # Frequency of training\n",
    "    gradient_steps=1,            # Gradient steps after each training step\n",
    "    target_update_interval=10000,# Number of steps before updating target network\n",
    "    exploration_fraction=0.1,    # Fraction of training period where exploration rate is annealed\n",
    "    exploration_final_eps=0.02,  # Final value of epsilon for exploration\n",
    "    exploration_initial_eps=1.0, # Initial value of epsilon for exploration\n",
    "    verbose=1,                   # Verbosity level\n",
    "    tensorboard_log=log_path     # TensorBoard log directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path + \"dqn_uav_swarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the UAV swarm environment simulation as a video (GIF or other formats).\n",
    "\n",
    "import imageio\n",
    "import time\n",
    "\n",
    "def saveVideo(env, model, filename=\"uav_simulation.mp4\", num_episodes=100, fps=10, deterministic=True, frame_delay=0.1):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - env: the environment instance\n",
    "    - model: the trained RL model\n",
    "    - filename: name of the file to save the video (should end with .gif, .mp4, etc.)\n",
    "    - num_episodes: number of episodes to record\n",
    "    - fps: frames per second for the output video\n",
    "    - deterministic: if True, use deterministic actions from the model\n",
    "    - frame_delay: time (in seconds) to wait between each frame (adjusts the simulation speed)\n",
    "    \"\"\"\n",
    "    frames = []  # Store frames to create video\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        print(f\"Recording Episode {episode + 1}/{num_episodes}\")\n",
    "        \n",
    "        while not done:\n",
    "            # Predict action using the trained model\n",
    "            action, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "            # Render and capture the frame\n",
    "            frame = env.render(mode='rgb_array')  # Get RGB array from render\n",
    "            plt.imshow(frame)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            frames.append(frame)\n",
    "            \n",
    "            if done or truncated:\n",
    "                break\n",
    "    \n",
    "    # Save the frames as a video file using imageio\n",
    "    print(f\"Saving video to {filename}\")\n",
    "    imageio.mimsave(filename, frames, fps=fps)  # Save as GIF or MP4\n",
    "    \n",
    "    print(f\"Video saved as {filename}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"./models/ppo_uav_swarm\")\n",
    "\n",
    "# Call the saveVideo function to record and save the video\n",
    "saveVideo(env, model, filename=\"uav_simulation.gif\", num_episodes=1, fps=1, deterministic=True, frame_delay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1ff9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
